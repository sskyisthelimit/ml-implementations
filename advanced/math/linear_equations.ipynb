{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число обумовленості матриці A: 29070279.007664092\n",
      "Матриця погано обумовлена.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "from scipy.sparse.linalg import cg\n",
    "from numpy.linalg import norm, cond\n",
    "\n",
    "A = np.arrayH6 = np.array([\n",
    "    [1, 1/2, 1/3, 1/4, 1/5, 1/6],\n",
    "    [1/2, 1/3, 1/4, 1/5, 1/6, 1/7],\n",
    "    [1/3, 1/4, 1/5, 1/6, 1/7, 1/8],\n",
    "    [1/4, 1/5, 1/6, 1/7, 1/8, 1/9],\n",
    "    [1/5, 1/6, 1/7, 1/8, 1/9, 1/10],\n",
    "    [1/6, 1/7, 1/8, 1/9, 1/10, 1/11]\n",
    "])\n",
    "\n",
    "condition_number = cond(A, p=np.inf)\n",
    "print(f\"Число обумовленості матриці A: {condition_number}\")\n",
    "if round(condition_number) > 1:\n",
    "    print(\"Матриця погано обумовлена.\")\n",
    "else:\n",
    "    print(\"Матриця добре обумовлена.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1.]\n",
      "[2.45       1.59285714 1.21785714 0.99563492 0.84563492 0.73654401]\n",
      "Метод спряжених градієнтів зійшовся за 6 ітерацій.\n",
      "Метод релаксації зійшовся за 582782 ітерацій.\n",
      "Розв'язок для b1 (метод спряжених градієнтів): [1.00000116 0.99996689 1.00022378 0.99941847 1.00064135 0.99974748]\n",
      "Розв'язок для b1 (метод релаксації): [1.0000047  0.99986983 1.00086324 0.99778725 1.00241518 0.99905676]\n"
     ]
    }
   ],
   "source": [
    "n = A.shape[0]\n",
    "x_real = np.ones(n)\n",
    "print(x_real)\n",
    "b1 = A @ x_real\n",
    "print(b1)\n",
    "\n",
    "def conjugate_gradient_method(A, b, x0=None, tol=1e-8, max_iter=1000):\n",
    "    n_iters = [0]\n",
    "    def callback(xk):\n",
    "        n_iters[0] += 1\n",
    "    \n",
    "    if x0 is None:\n",
    "        x0 = np.zeros(len(b))\n",
    "    x, info = cg(A, b, x0=x0, rtol=tol, maxiter=max_iter, callback=callback)\n",
    "    if info == 0:\n",
    "        print(f\"Метод спряжених градієнтів зійшовся за {n_iters[0]} ітерацій.\")\n",
    "    else:\n",
    "        print(\"Метод спряжених градієнтів не зійшовся.\")\n",
    "    return x\n",
    "\n",
    "def relaxation_method(A, b, omega=1.25, tol=1e-8, max_iter=1000000):\n",
    "    n = len(b)\n",
    "    x = np.zeros(n)\n",
    "    for iteration in range(max_iter):\n",
    "        x_old = x.copy()\n",
    "        for i in range(n):\n",
    "            sigma = sum(A[i, j] * x[j] for j in range(n) if j != i)\n",
    "            x[i] = (1 - omega) * x[i] + (omega / A[i, i]) * (b[i] - sigma)\n",
    "        if norm(x - x_old, ord=2) < tol:\n",
    "            print(f\"Метод релаксації зійшовся за {iteration+1} ітерацій.\")\n",
    "            return x\n",
    "    print(\"Метод релаксації не зійшовся.\")\n",
    "    return x\n",
    "\n",
    "x_cg_b1 = conjugate_gradient_method(A, b1)\n",
    "x_relax_b1 = relaxation_method(A, b1)\n",
    "\n",
    "print(\"Розв'язок для b1 (метод спряжених градієнтів):\", x_cg_b1)\n",
    "print(\"Розв'язок для b1 (метод релаксації):\", x_relax_b1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1 and b2 norm value: 2.449489742783171\n",
      "b1 and b3 norm value: 1.3472193585307537\n"
     ]
    }
   ],
   "source": [
    "b2 = b1 + 0.01\n",
    "b3 = b1  + 0.0055\n",
    "print(f\"b1 and b2 norm value: {np.linalg.norm(b2 - b1, ord=2) * 100}\")\n",
    "print(f\"b1 and b3 norm value: {np.linalg.norm(b1 - b3, ord=2) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метод спряжених градієнтів зійшовся за 8 ітерацій.\n",
      "Метод релаксації не зійшовся.\n",
      "Метод спряжених градієнтів зійшовся за 8 ітерацій.\n",
      "Метод релаксації не зійшовся.\n",
      "Error comparison for relaxation method x:\n",
      "Percentage Error for solving using original vector b 0.35186923236782525\n",
      "Percentage Error for solving using vector b1 (b + 0.01): 8170.718761624336\n",
      "Percentage Error for solving using vector b1 (b + 0.0055): 4493.847197084842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_cg_b2 = conjugate_gradient_method(A, b2)\n",
    "x_relax_b2 = relaxation_method(A, b2)\n",
    "\n",
    "x_cg_b3 = conjugate_gradient_method(A, b3)\n",
    "x_relax_b3 = relaxation_method(A, b3)\n",
    "\n",
    "print(\"Error comparison for relaxation method x:\")\n",
    "print(\"Percentage Error for solving using original vector b\", np.linalg.norm(x_relax_b1 - x_real) * 100)\n",
    "\n",
    "print(\"Percentage Error for solving using vector b1 (b + 0.01):\", np.linalg.norm(x_relax_b2 - x_real) * 100)\n",
    "\n",
    "print(\"Percentage Error for solving using vector b1 (b + 0.0055):\", np.linalg.norm(x_relax_b3 - x_real) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error comparison for conjugate gradient method x:\n",
      "Percentage Error for solving using original vector b 0.09297599820824355\n",
      "Percentage Error for solving using vector b1 (b + 0.01): 8697.247841176102\n",
      "Percentage Error for solving using vector b1 (b + 0.0055): 4783.48631278829\n"
     ]
    }
   ],
   "source": [
    "print(\"Error comparison for conjugate gradient method x:\")\n",
    "print(\"Percentage Error for solving using original vector b\", np.linalg.norm(x_cg_b1 - x_real) * 100)\n",
    "\n",
    "print(\"Percentage Error for solving using vector b1 (b + 0.01):\", np.linalg.norm(x_cg_b2 - x_real) * 100)\n",
    "\n",
    "print(\"Percentage Error for solving using vector b1 (b + 0.0055):\", np.linalg.norm(x_cg_b3 - x_real) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [ 5.10477598e+01  3.13895815e+01 -1.11881843e-15  1.25626587e+01]\n",
      "Non-zero eigenvalues: [51.04775977798845, 31.389581519597307, 12.562658702414323]\n",
      "Product of non-zero eigenvalues: 20130.000000000044\n",
      "x_real: [1. 2. 3. 4.]\n",
      "b1: [12.  2.  6. 10.]\n",
      "A^T b1: [ 50.  44.  62. -10.]\n",
      "Computed x: [1. 2. 3. 4.]\n",
      "A^T * A after 1th column change: \n",
      " [[ 50  -2  -7   9]\n",
      " [ 44  15   8  -2]\n",
      " [ 62   8  35 -13]\n",
      " [-10  -2 -13   6]]\n",
      "\n",
      " A^T * A after column 2th and row 2th deletion: \n",
      " [[ 50  -7   9]\n",
      " [ 62  35 -13]\n",
      " [-10 -13   6]]\n",
      "Determinant value for current component: -360.0000000000023\n",
      "\n",
      " A^T * A after column 3th and row 3th deletion: \n",
      " [[ 50  -2   9]\n",
      " [ 44  15  -2]\n",
      " [-10  -2   6]]\n",
      "Determinant value for current component: 5345.999999999995\n",
      "\n",
      " A^T * A after column 4th and row 4th deletion: \n",
      " [[50 -2 -7]\n",
      " [44 15  8]\n",
      " [62  8 35]]\n",
      "Determinant value for current component: 29184.0\n",
      "A^T * A after 2th column change: \n",
      " [[ 39  50  -7   9]\n",
      " [ -2  44   8  -2]\n",
      " [ -7  62  35 -13]\n",
      " [  9 -10 -13   6]]\n",
      "\n",
      " A^T * A after column 1th and row 1th deletion: \n",
      " [[ 44   8  -2]\n",
      " [ 62  35 -13]\n",
      " [-10 -13   6]]\n",
      "Determinant value for current component: 779.9999999999994\n",
      "\n",
      " A^T * A after column 3th and row 3th deletion: \n",
      " [[ 39  50   9]\n",
      " [ -2  44  -2]\n",
      " [  9 -10   6]]\n",
      "Determinant value for current component: 5832.000000000002\n",
      "\n",
      " A^T * A after column 4th and row 4th deletion: \n",
      " [[39 50 -7]\n",
      " [-2 44  8]\n",
      " [-7 62 35]]\n",
      "Determinant value for current component: 40127.99999999999\n",
      "A^T * A after 3th column change: \n",
      " [[ 39  -2  50   9]\n",
      " [ -2  15  44  -2]\n",
      " [ -7   8  62 -13]\n",
      " [  9  -2 -10   6]]\n",
      "\n",
      " A^T * A after column 1th and row 1th deletion: \n",
      " [[ 15  44  -2]\n",
      " [  8  62 -13]\n",
      " [ -2 -10   6]]\n",
      "Determinant value for current component: 2574.000000000001\n",
      "\n",
      " A^T * A after column 2th and row 2th deletion: \n",
      " [[ 39  50   9]\n",
      " [ -7  62 -13]\n",
      " [  9 -10   6]]\n",
      "Determinant value for current component: 1295.9999999999986\n",
      "\n",
      " A^T * A after column 4th and row 4th deletion: \n",
      " [[39 -2 50]\n",
      " [-2 15 44]\n",
      " [-7  8 62]]\n",
      "Determinant value for current component: 27360.000000000004\n",
      "A^T * A after 4th column change: \n",
      " [[ 39  -2  -7  50]\n",
      " [ -2  15   8  44]\n",
      " [ -7   8  35  62]\n",
      " [  9  -2 -13 -10]]\n",
      "\n",
      " A^T * A after column 1th and row 1th deletion: \n",
      " [[ 15   8  44]\n",
      " [  8  35  62]\n",
      " [ -2 -13 -10]]\n",
      "Determinant value for current component: 4991.999999999998\n",
      "\n",
      " A^T * A after column 2th and row 2th deletion: \n",
      " [[ 39  -7  50]\n",
      " [ -7  35  62]\n",
      " [  9 -13 -10]]\n",
      "Determinant value for current component: 3167.999999999998\n",
      "\n",
      " A^T * A after column 3th and row 3th deletion: \n",
      " [[ 39  -2  50]\n",
      " [ -2  15  44]\n",
      " [  9  -2 -10]]\n",
      "Determinant value for current component: -9720.000000000002\n",
      "x_values: [1.6974664679582672, 2.32190760059612, 1.5514157973174334, -0.0774962742175858]\n",
      "A^T A x_values: [ 50.  44.  62. -10.]\n",
      "relative euclidean norm = 0.00000000000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the matrix A\n",
    "A = np.array([\n",
    "    [2, 1, 4, -1],\n",
    "    [3, -2, 1, 0],\n",
    "    [5, 1, -3, 2],\n",
    "    [-1, 3, 3, -1]\n",
    "])\n",
    "\n",
    "# Compute A^T A\n",
    "AtA = np.transpose(A) @ A\n",
    "\n",
    "# Compute eigenvalues of A^T A\n",
    "eigenvalues = np.linalg.eigvals(AtA)\n",
    "non_zero_eig = [eig for eig in eigenvalues if eig > 1e-10]\n",
    "non_zero_eig_prod = np.prod(non_zero_eig)\n",
    "print(\"Eigenvalues:\", eigenvalues)\n",
    "print(\"Non-zero eigenvalues:\", non_zero_eig)\n",
    "print(\"Product of non-zero eigenvalues:\", non_zero_eig_prod)\n",
    "\n",
    "# Define x_real\n",
    "n = A.shape[0]\n",
    "x_real = np.ones(n)\n",
    "for i in range(n):\n",
    "    x_real[i] = np.float32(i+1)\n",
    "print(\"x_real:\", x_real)\n",
    "\n",
    "# Compute b1\n",
    "b1 = A @ x_real\n",
    "AtB = np.transpose(A) @ b1\n",
    "print(\"b1:\", b1)\n",
    "print(\"A^T b1:\", AtB)\n",
    "\n",
    "# Solution using np.linalg.solve for comparison\n",
    "x_computed = np.linalg.solve(A, b1)\n",
    "print(\"Computed x:\", x_computed)\n",
    "\n",
    "# Solution using the updated method\n",
    "x_values = []\n",
    "for i in range(4):\n",
    "    A_new = AtA.copy()\n",
    "    A_new[:, i] = AtB\n",
    "    print(f\"A^T * A after {i+1}th column change: \\n {A_new}\")\n",
    "\n",
    "    det_values = []\n",
    "    cur_range = [j for j in range(4) if j != i]\n",
    "    for idx in cur_range:\n",
    "        A_subloop = np.delete(A_new, idx, axis=0)\n",
    "        A_subloop = np.delete(A_subloop, idx, axis=1)\n",
    "        print(f\"\\n A^T * A after column {idx + 1}th and row {idx + 1}th deletion: \\n {A_subloop}\")\n",
    "        current_det = np.linalg.det(A_subloop)\n",
    "        print(f\"Determinant value for current component: {current_det}\")\n",
    "        det_values.append(current_det)\n",
    "    x_values.append(np.sum(np.array(det_values)) / non_zero_eig_prod)\n",
    "\n",
    "print(\"x_values:\", x_values)\n",
    "print(\"A^T A x_values:\", AtA @ x_values)\n",
    "print(\"relative euclidean norm = %.14f\" % (np.linalg.norm((AtA @ x_values) - AtB) / np.linalg.norm(AtB)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Комбінований метод\n",
      "Умова збіжності не виконана.\n",
      "\n",
      "=== Точність ε = 0.1 ===\n",
      "=== Наближення x = (-0.8, -0.2) ===\n",
      "Метод січних\n",
      "Ітерація 1: x = -0.34843915134758363, f(x) = -0.04310482592051912\n",
      "Ітерація 2: x = -0.3775980486087703, f(x) = 0.003806116588209285\n",
      "Корінь знайдено з точністю 0.1: x = -0.3775980486087703\n",
      "Комбінований метод\n",
      "Умова збіжності виконана.\n",
      "n = 0, x = -0.8, z1 = -0.2, Δx = 1\n",
      "n = 1, x1 = -0.41993, x2 = -0.34844, x = -0.38418,   Δx = 0.07149045\n",
      "Обчислення завершено.\n",
      "=== Наближення x = (-10, 0) ===\n",
      "Метод січних\n",
      "Ітерація 1: x = -0.17857084949256968, f(x) = -0.29135786817845055\n",
      "Ітерація 2: x = -0.42793573841859617, f(x) = 0.08751382040958244\n",
      "Ітерація 3: x = -0.37033609515346716, f(x) = -0.007987280170033806\n",
      "Корінь знайдено з точністю 0.1: x = -0.37033609515346716\n",
      "Комбінований метод\n",
      "Умова збіжності виконана.\n",
      "n = 0, x = -10, z1 = 0, Δx = 1\n",
      "n = 1, x1 = -0.83303, x2 = -0.17857, x = -0.50580,   Δx = 0.65445476\n",
      "n = 2, x1 = -0.42536, x2 = -0.34296, x = -0.38416,   Δx = 0.08239760\n",
      "Обчислення завершено.\n",
      "\n",
      "=== Точність ε = 0.01 ===\n",
      "=== Наближення x = (-0.8, -0.2) ===\n",
      "Метод січних\n",
      "Ітерація 1: x = -0.34843915134758363, f(x) = -0.04310482592051912\n",
      "Ітерація 2: x = -0.3775980486087703, f(x) = 0.003806116588209285\n",
      "Ітерація 3: x = -0.37523224317778703, f(x) = -4.3912309646287895e-05\n",
      "Корінь знайдено з точністю 0.01: x = -0.37523224317778703\n",
      "Комбінований метод\n",
      "Умова збіжності виконана.\n",
      "n = 0, x = -0.8, z1 = -0.2, Δx = 1\n",
      "n = 1, x1 = -0.41993, x2 = -0.34844, x = -0.38418,   Δx = 0.07149045\n",
      "n = 2, x1 = -0.37605, x2 = -0.37476, x = -0.37540,   Δx = 0.00128922\n",
      "Обчислення завершено.\n",
      "=== Наближення x = (-10, 0) ===\n",
      "Метод січних\n",
      "Ітерація 1: x = -0.17857084949256968, f(x) = -0.29135786817845055\n",
      "Ітерація 2: x = -0.42793573841859617, f(x) = 0.08751382040958244\n",
      "Ітерація 3: x = -0.37033609515346716, f(x) = -0.007987280170033806\n",
      "Ітерація 4: x = -0.37515346883461176, f(x) = -0.0001719746968560365\n",
      "Корінь знайдено з точністю 0.01: x = -0.37515346883461176\n",
      "Комбінований метод\n",
      "Умова збіжності виконана.\n",
      "n = 0, x = -10, z1 = 0, Δx = 1\n",
      "n = 1, x1 = -0.83303, x2 = -0.17857, x = -0.50580,   Δx = 0.65445476\n",
      "n = 2, x1 = -0.42536, x2 = -0.34296, x = -0.38416,   Δx = 0.08239760\n",
      "n = 3, x1 = -0.37624, x2 = -0.37458, x = -0.37541,   Δx = 0.00166047\n",
      "Обчислення завершено.\n",
      "\n",
      "=== Точність ε = 0.001 ===\n",
      "=== Наближення x = (-0.8, -0.2) ===\n",
      "Метод січних\n",
      "Ітерація 1: x = -0.34843915134758363, f(x) = -0.04310482592051912\n",
      "Ітерація 2: x = -0.3775980486087703, f(x) = 0.003806116588209285\n",
      "Ітерація 3: x = -0.37523224317778703, f(x) = -4.3912309646287895e-05\n",
      "Ітерація 4: x = -0.3752592268663266, f(x) = -4.3330212307068905e-08\n",
      "Корінь знайдено з точністю 0.001: x = -0.3752592268663266\n",
      "Комбінований метод\n",
      "Умова збіжності виконана.\n",
      "n = 0, x = -0.8, z1 = -0.2, Δx = 1\n",
      "n = 1, x1 = -0.41993, x2 = -0.34844, x = -0.38418,   Δx = 0.07149045\n",
      "n = 2, x1 = -0.37605, x2 = -0.37476, x = -0.37540,   Δx = 0.00128922\n",
      "Обчислення завершено.\n",
      "=== Наближення x = (-10, 0) ===\n",
      "Метод січних\n",
      "Ітерація 1: x = -0.17857084949256968, f(x) = -0.29135786817845055\n",
      "Ітерація 2: x = -0.42793573841859617, f(x) = 0.08751382040958244\n",
      "Ітерація 3: x = -0.37033609515346716, f(x) = -0.007987280170033806\n",
      "Ітерація 4: x = -0.37515346883461176, f(x) = -0.0001719746968560365\n",
      "Ітерація 5: x = -0.3752594744643725, f(x) = 3.5920921703791464e-07\n",
      "Корінь знайдено з точністю 0.001: x = -0.3752594744643725\n",
      "Комбінований метод\n",
      "Умова збіжності виконана.\n",
      "n = 0, x = -10, z1 = 0, Δx = 1\n",
      "n = 1, x1 = -0.83303, x2 = -0.17857, x = -0.50580,   Δx = 0.65445476\n",
      "n = 2, x1 = -0.42536, x2 = -0.34296, x = -0.38416,   Δx = 0.08239760\n",
      "n = 3, x1 = -0.37624, x2 = -0.37458, x = -0.37541,   Δx = 0.00166047\n",
      "Обчислення завершено.\n",
      "\n",
      "=== Точність ε = 1e-06 ===\n",
      "=== Наближення x = (-0.8, -0.2) ===\n",
      "Метод січних\n",
      "Ітерація 1: x = -0.34843915134758363, f(x) = -0.04310482592051912\n",
      "Ітерація 2: x = -0.3775980486087703, f(x) = 0.003806116588209285\n",
      "Ітерація 3: x = -0.37523224317778703, f(x) = -4.3912309646287895e-05\n",
      "Ітерація 4: x = -0.3752592268663266, f(x) = -4.3330212307068905e-08\n",
      "Ітерація 5: x = -0.375259253518621, f(x) = 4.947153797729698e-13\n",
      "Корінь знайдено з точністю 1e-06: x = -0.375259253518621\n",
      "Комбінований метод\n",
      "Умова збіжності виконана.\n",
      "n = 0, x = -0.8, z1 = -0.2, Δx = 1\n",
      "n = 1, x1 = -0.41993, x2 = -0.34844, x = -0.38418,   Δx = 0.07149045\n",
      "n = 2, x1 = -0.37605, x2 = -0.37476, x = -0.37540,   Δx = 0.00128922\n",
      "n = 3, x1 = -0.37526, x2 = -0.37526, x = -0.37526,   Δx = 0.00000043\n",
      "Обчислення завершено.\n",
      "=== Наближення x = (-10, 0) ===\n",
      "Метод січних\n",
      "Ітерація 1: x = -0.17857084949256968, f(x) = -0.29135786817845055\n",
      "Ітерація 2: x = -0.42793573841859617, f(x) = 0.08751382040958244\n",
      "Ітерація 3: x = -0.37033609515346716, f(x) = -0.007987280170033806\n",
      "Ітерація 4: x = -0.37515346883461176, f(x) = -0.0001719746968560365\n",
      "Ітерація 5: x = -0.3752594744643725, f(x) = 3.5920921703791464e-07\n",
      "Ітерація 6: x = -0.375259253508438, f(x) = -1.6060930363437365e-11\n",
      "Корінь знайдено з точністю 1e-06: x = -0.375259253508438\n",
      "Комбінований метод\n",
      "Умова збіжності виконана.\n",
      "n = 0, x = -10, z1 = 0, Δx = 1\n",
      "n = 1, x1 = -0.83303, x2 = -0.17857, x = -0.50580,   Δx = 0.65445476\n",
      "n = 2, x1 = -0.42536, x2 = -0.34296, x = -0.38416,   Δx = 0.08239760\n",
      "n = 3, x1 = -0.37624, x2 = -0.37458, x = -0.37541,   Δx = 0.00166047\n",
      "n = 4, x1 = -0.37526, x2 = -0.37526, x = -0.37526,   Δx = 0.00000069\n",
      "Обчислення завершено.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Функція для обчислення значення f(x)\n",
    "def f(x):\n",
    "    return 2 * math.exp(x) - 3 * x - 2.5\n",
    "\n",
    "# Похідна f(x) для методу Ньютона\n",
    "def f_prime(x):\n",
    "    return 2 * math.exp(x) - 3\n",
    "\n",
    "# Метод січних\n",
    "def secant_method(x0, x1, epsilon, max_iter):\n",
    "    print(\"Метод січних\")\n",
    "    for i in range(max_iter):\n",
    "        f_x0 = f(x0)\n",
    "        f_x1 = f(x1)\n",
    "        x2 = x1 - f_x1 * (x1 - x0) / (f_x1 - f_x0)\n",
    "        \n",
    "        # Вивід результатів ітерації\n",
    "        print(f\"Ітерація {i+1}: x = {x2}, f(x) = {f(x2)}\")\n",
    "        \n",
    "        # Перевірка на точність\n",
    "        if abs(x2 - x1) < epsilon:\n",
    "            print(f\"Корінь знайдено з точністю {epsilon}: x = {x2}\")\n",
    "            return x2\n",
    "        \n",
    "        x0 = x1\n",
    "        x1 = x2\n",
    "\n",
    "    print(\"Максимальна кількість ітерацій досягнута\")\n",
    "    return x2\n",
    "\n",
    "def f_double_prime(x):\n",
    "    return 2 * math.exp(x)\n",
    "\n",
    "def combined_method(a, b, epsilon, max_iter=10):\n",
    "    print(\"Комбінований метод\")\n",
    "    \n",
    "    x = a  # Початкове значення для методу дотичних\n",
    "    z0, z1 = a, b  # Початкові значення для методу січних\n",
    "    \n",
    "    ep = 1  # Початкова похибка\n",
    "    n = 0  # Лічильник ітерацій\n",
    "    \n",
    "    # Перевірка умови збіжності\n",
    "    if f_double_prime(x) * f(x) > 0:\n",
    "        print(\"Умова збіжності виконана.\")\n",
    "    else:\n",
    "        print(\"Умова збіжності не виконана.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"n = {n}, x = {x}, z1 = {z1}, Δx = {ep}\")\n",
    "    \n",
    "    # Ітерації комбінованого методу\n",
    "    while ep > 2*epsilon and n < max_iter:\n",
    "        # Метод січних\n",
    "        z1 = z1 - f(z1) * (z0 - z1) / (f(z0) - f(z1))\n",
    "        \n",
    "        # Метод дотичних (Ньютона)\n",
    "        x = x - f(x) / f_prime(x)\n",
    "        \n",
    "        # Обчислення похибки\n",
    "        ep = abs(z1 - x)\n",
    "        \n",
    "        # Підготовка до наступної ітерації\n",
    "        z0 = x\n",
    "        n += 1\n",
    "        \n",
    "        # Вивід результатів ітерації\n",
    "        print(f\"n = {n}, x1 = {x:.5f}, x2 = {z1:.5f}, x = {((x + z1) / 2):.5f},   Δx = {ep:.8f}\")\n",
    "    \n",
    "    print(\"Обчислення завершено.\")\n",
    "    return (x + z1) / 2 \n",
    "\n",
    "# Приклад виклику функції\n",
    "a = 1.0\n",
    "b = 1.5\n",
    "epsilon = 0.001\n",
    "combined_method(a, b, epsilon)\n",
    "\n",
    "\n",
    "# Параметри\n",
    "epsilon_values = [0.1, 0.01, 0.001, 1e-6]\n",
    "approximations = [(-0.8, -0.2), (-10, 0)]\n",
    "\n",
    "max_iter = 100\n",
    "\n",
    "# Запуск методів для різних значень точності\n",
    "for epsilon in epsilon_values:\n",
    "    print(f\"\\n=== Точність ε = {epsilon} ===\")\n",
    "    for x0, x1 in approximations:\n",
    "        print(f\"=== Наближення x = {(x0, x1)} ===\")\n",
    "        secant_root = secant_method(x0, x1, epsilon, max_iter)\n",
    "        combined_root = combined_method(x0, x1, epsilon, max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector b = Ax: \n",
      "[2.45       1.59285714 1.21785714 0.99563492 0.84563492 0.73654401]\n",
      "Matrix A^T: \n",
      "[[1.         0.5        0.33333333 0.25       0.2        0.16666667]\n",
      " [0.5        0.33333333 0.25       0.2        0.16666667 0.14285714]\n",
      " [0.33333333 0.25       0.2        0.16666667 0.14285714 0.125     ]\n",
      " [0.25       0.2        0.16666667 0.14285714 0.125      0.11111111]\n",
      " [0.2        0.16666667 0.14285714 0.125      0.11111111 0.1       ]\n",
      " [0.16666667 0.14285714 0.125      0.11111111 0.1        0.09090909]]\n",
      "Matrix A^T * A: \n",
      "[[1.49138889 0.85714286 0.61607143 0.48478836 0.40109127 0.3426912 ]\n",
      " [0.85714286 0.51179705 0.375      0.29861111 0.24907407 0.21407828]\n",
      " [0.61607143 0.375      0.27742205 0.22222222 0.18611111 0.16043771]\n",
      " [0.48478836 0.29861111 0.22222222 0.17865662 0.15       0.12954545]\n",
      " [0.40109127 0.24907407 0.18611111 0.15       0.12615662 0.10909091]\n",
      " [0.3426912  0.21407828 0.16043771 0.12954545 0.10909091 0.09442108]]\n",
      "Vector A^T * b: \n",
      "[4.193174   2.50570338 1.83726452 1.46382377 1.22152398 1.05026464]\n",
      "Solution x = [1.00293803 0.97318895 1.029234   1.02963114 1.000554   0.95915167]\n",
      "Converged in 1656530 steps\n",
      "Stopping criteria value 9.999996636653286e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Define the ill-conditioned matrix H6\n",
    "H6 = np.array([\n",
    "    [1, 1/2, 1/3, 1/4, 1/5, 1/6],\n",
    "    [1/2, 1/3, 1/4, 1/5, 1/6, 1/7],\n",
    "    [1/3, 1/4, 1/5, 1/6, 1/7, 1/8],\n",
    "    [1/4, 1/5, 1/6, 1/7, 1/8, 1/9],\n",
    "    [1/5, 1/6, 1/7, 1/8, 1/9, 1/10],\n",
    "    [1/6, 1/7, 1/8, 1/9, 1/10, 1/11]\n",
    "])\n",
    "\n",
    "# Define x\n",
    "x = np.ones(6)\n",
    "\n",
    "# Step 1: Calculate b = H6 * x\n",
    "b = np.dot(H6, x)\n",
    "print(f\"Vector b = Ax: \\n{b}\")\n",
    "# Compute A^T and A^T * A\n",
    "A_T = H6.T\n",
    "print(f\"Matrix A^T: \\n{A_T}\")\n",
    "ATA = np.dot(A_T, H6)\n",
    "print(f\"Matrix A^T * A: \\n{ATA}\")\n",
    "ATb = np.dot(A_T, b)\n",
    "print(f\"Vector A^T * b: \\n{ATb}\")\n",
    "\n",
    "\n",
    "# Define the ODE function dx/dt = A^T b - A^T A x\n",
    "def dx_dt(x, ATA, ATb):\n",
    "    return ATb - np.dot(ATA, x)\n",
    "\n",
    "# Adams-Bashforth Method\n",
    "def adams_bashforth(ATA, ATb, dt=0.01, beta=1e-6, max_steps=2000000):\n",
    "    x_t = np.zeros(6)  # Initial condition x(0) = 0\n",
    "    x_prev = x_t.copy()\n",
    "    step = 0\n",
    "\n",
    "    # Perform Euler step for initialization\n",
    "    f_t = dx_dt(x_t, ATA, ATb)\n",
    "    x_t += dt * f_t\n",
    "    step += 1\n",
    "\n",
    "    while step <= max_steps:\n",
    "        # Calculate f_t+1\n",
    "        f_t_next = dx_dt(x_t, ATA, ATb)\n",
    "\n",
    "        # Adams-Bashforth formula: x_t+1 = x_t + dt * (3/2 * f_t_next - 1/2 * f_t)\n",
    "        x_next = x_t + dt * (3/2 * f_t_next - 1/2 * f_t)\n",
    "\n",
    "        if step == max_steps:\n",
    "            return x_next, -1, norm(np.dot(ATA, x_next) - ATb)\n",
    "        # Stopping criterion\n",
    "        if norm(np.dot(ATA, x_next) - ATb) < beta:\n",
    "            return x_next, step, norm(np.dot(ATA, x_next) - ATb)\n",
    "\n",
    "        # Update for next iteration\n",
    "        x_prev = x_t\n",
    "        x_t = x_next\n",
    "        f_t = f_t_next\n",
    "        step += 1\n",
    "\n",
    "# Solve the system\n",
    "x_solution, steps, criteria_val = adams_bashforth(ATA, ATb)\n",
    "print(f\"Solution x = {x_solution}\")\n",
    "print(f\"Converged in {steps} steps\" if steps != -1 else \"Max steps exceeded without convergence\")\n",
    "print(f\"Stopping criteria value {criteria_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution x: \n",
      " [[1.00293803]\n",
      " [0.97318895]\n",
      " [1.029234  ]\n",
      " [1.02963114]\n",
      " [1.000554  ]\n",
      " [0.95915167]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Solution x: \\n {x_solution[:, None]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution x for b1: \n",
      " [[1.02982978]\n",
      " [0.85981777]\n",
      " [1.00244623]\n",
      " [1.0733581 ]\n",
      " [1.09051567]\n",
      " [1.07818396]]\n",
      "Converged in 1871142 steps\n",
      "Stopping criteria value 9.999994898656237e-07\n"
     ]
    }
   ],
   "source": [
    "beta = 0.01\n",
    "beta_2 = 0.0055\n",
    "b1 = b + beta\n",
    "b2 = b + beta_2\n",
    "\n",
    "ATb1 = np.dot(A_T, b1)\n",
    "\n",
    "x_b1_solution, steps, criteria_val = adams_bashforth(ATA, ATb1)\n",
    "print(f\"Solution x for b1: \\n {x_b1_solution[:, None]}\")\n",
    "print(f\"Converged in {steps} steps\" if steps != -1 else \"Max steps exceeded without convergence\")\n",
    "print(f\"Stopping criteria value {criteria_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution x for b2: \n",
      " [[1.0177225 ]\n",
      " [0.91078938]\n",
      " [1.01462683]\n",
      " [1.05375553]\n",
      " [1.04999559]\n",
      " [1.0244706 ]]\n",
      "Converged in 1776449 steps\n",
      "Stopping criteria value 9.999993321652367e-07\n"
     ]
    }
   ],
   "source": [
    "ATb2 = np.dot(A_T, b2)\n",
    "\n",
    "x_b2_solution, steps, criteria_val = adams_bashforth(ATA, ATb2)\n",
    "print(f\"Solution x for b2: \\n {x_b2_solution[:, None]}\")\n",
    "print(f\"Converged in {steps} steps\" if steps != -1 else \"Max steps exceeded without convergence\")\n",
    "print(f\"Stopping criteria value {criteria_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Error for solving using original vector b: 2.623289434300295\n",
      "Percentage Error for solving using vector b + 0.01: 8.188822436755439\n",
      "Percentage Error for solving using vector b + 0.0055: 4.911651571121093\n"
     ]
    }
   ],
   "source": [
    "orig_x_norm = np.linalg.norm(x)\n",
    "err_0 = np.linalg.norm(x - x_solution) / orig_x_norm\n",
    "err_1 = np.linalg.norm(x - x_b1_solution) / orig_x_norm\n",
    "err_2 = np.linalg.norm(x - x_b2_solution) / orig_x_norm\n",
    "\n",
    "print(\"Percentage Error for solving using original vector b: {}\".format(err_0 * 100))\n",
    "print(\"Percentage Error for solving using vector b + 0.01: {}\".format(err_1 * 100))\n",
    "print(\"Percentage Error for solving using vector b + 0.0055: {}\".format(err_2 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector b1 (b + 0.01): \n",
      " [[2.46      ]\n",
      " [1.60285714]\n",
      " [1.22785714]\n",
      " [1.00563492]\n",
      " [0.85563492]\n",
      " [0.74654401]]\n",
      "Vector b2 (b + 0.0055): \n",
      " [[2.4555    ]\n",
      " [1.59835714]\n",
      " [1.22335714]\n",
      " [1.00113492]\n",
      " [0.85113492]\n",
      " [0.74204401]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vector b1 (b + 0.01): \\n {b1[:, None]}\")\n",
    "print(f\"Vector b2 (b + 0.0055): \\n {b2[:, None]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1 & b norm (b1 = b + 0.01) 0.024494897427831713\n",
      "b2 & b norm (b2 = b + 0.0055) 0.013472193585307537\n"
     ]
    }
   ],
   "source": [
    "print(f\"b1 & b norm (b1 = b + 0.01) {np.linalg.norm(b-b1)}\")\n",
    "print(f\"b2 & b norm (b2 = b + 0.0055) {np.linalg.norm(b-b2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
